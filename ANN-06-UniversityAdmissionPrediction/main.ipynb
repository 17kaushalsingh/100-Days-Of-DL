{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit ']\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "cols = cols.to_list()\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Chance of Admit '])\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0        337          118                  4  4.5   4.5  9.65         1\n",
       "1        324          107                  4  4.0   4.5  8.87         1\n",
       "2        316          104                  3  3.0   3.5  8.00         1\n",
       "3        322          110                  3  3.5   2.5  8.67         1\n",
       "4        314          103                  2  2.0   3.0  8.21         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.92\n",
       "1    0.76\n",
       "2    0.72\n",
       "3    0.80\n",
       "4    0.65\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68      ,  0.64285714,  0.5       ,  0.625     ,  0.5       ,\n",
       "         0.74264706,  1.        ],\n",
       "       [ 0.7       ,  0.78571429,  1.        ,  0.75      ,  1.        ,\n",
       "         0.83088235,  1.        ],\n",
       "       [ 0.16      ,  0.32142857,  0.75      ,  0.375     ,  0.875     ,\n",
       "         0.18014706,  1.        ],\n",
       "       [ 0.42      ,  0.5       ,  0.25      ,  0.625     ,  0.5       ,\n",
       "         0.38970588,  1.        ],\n",
       "       [ 0.62      ,  0.78571429,  0.75      ,  0.75      ,  1.        ,\n",
       "         0.70588235,  0.        ],\n",
       "       [ 0.54      ,  0.5       ,  0.5       ,  0.75      ,  0.625     ,\n",
       "         0.47794118,  1.        ],\n",
       "       [ 0.28      ,  0.39285714,  1.        ,  1.        ,  0.75      ,\n",
       "         0.52941176,  0.        ],\n",
       "       [ 0.86      ,  0.96428571,  1.        ,  1.        ,  0.875     ,\n",
       "         0.94852941,  1.        ],\n",
       "       [ 0.82      ,  0.82142857,  1.        ,  0.875     ,  0.625     ,\n",
       "         0.79411765,  1.        ],\n",
       "       [ 0.54      ,  0.39285714,  0.25      ,  0.375     ,  0.25      ,\n",
       "         0.34926471,  0.        ],\n",
       "       [ 0.48      ,  0.64285714,  0.5       ,  0.75      ,  0.75      ,\n",
       "         0.58823529,  0.        ],\n",
       "       [ 0.84      ,  0.89285714,  0.75      ,  0.875     ,  0.75      ,\n",
       "         0.69852941,  0.        ],\n",
       "       [ 0.86      ,  0.92857143,  1.        ,  1.        ,  1.        ,\n",
       "         0.79044118,  1.        ],\n",
       "       [ 0.64      ,  0.42857143,  0.5       ,  0.625     ,  0.75      ,\n",
       "         0.60294118,  1.        ],\n",
       "       [ 0.46      ,  0.5       ,  0.25      ,  0.375     ,  0.25      ,\n",
       "         0.45220588,  0.        ],\n",
       "       [ 0.18      ,  0.5       ,  0.25      ,  0.75      ,  0.75      ,\n",
       "         0.44117647,  0.        ],\n",
       "       [ 0.36      ,  0.5       ,  0.5       ,  0.625     ,  0.375     ,\n",
       "         0.37132353,  1.        ],\n",
       "       [ 0.44      ,  0.21428571,  0.        ,  0.625     ,  0.5       ,\n",
       "         0.36029412,  1.        ],\n",
       "       [ 0.52      ,  0.64285714,  0.5       ,  0.75      ,  0.875     ,\n",
       "         0.58088235,  1.        ],\n",
       "       [ 0.58      ,  0.46428571,  0.5       ,  0.5       ,  0.625     ,\n",
       "         0.54044118,  1.        ],\n",
       "       [ 0.56      ,  0.28571429,  0.25      ,  0.375     ,  0.625     ,\n",
       "         0.49264706,  1.        ],\n",
       "       [ 0.3       ,  0.53571429,  0.25      ,  0.375     ,  0.375     ,\n",
       "         0.44852941,  0.        ],\n",
       "       [ 0.44      ,  0.39285714,  0.75      ,  0.75      ,  1.        ,\n",
       "         0.45220588,  0.        ],\n",
       "       [ 0.78      ,  0.67857143,  0.75      ,  0.875     ,  0.75      ,\n",
       "         0.66544118,  1.        ],\n",
       "       [ 0.98      ,  0.85714286,  0.75      ,  0.75      ,  0.625     ,\n",
       "         0.95588235,  1.        ],\n",
       "       [ 0.68      ,  0.53571429,  1.        ,  0.625     ,  0.75      ,\n",
       "         0.53676471,  1.        ],\n",
       "       [ 0.42      ,  0.42857143,  0.5       ,  0.625     ,  0.25      ,\n",
       "         0.36764706,  1.        ],\n",
       "       [ 0.58      ,  0.5       ,  0.5       ,  0.625     ,  0.375     ,\n",
       "         0.41544118,  1.        ],\n",
       "       [ 0.8       ,  0.85714286,  1.        ,  1.        ,  0.875     ,\n",
       "         0.79411765,  1.        ],\n",
       "       [ 0.8       ,  0.85714286,  0.75      ,  1.        ,  0.875     ,\n",
       "         0.82720588,  1.        ],\n",
       "       [ 0.88      ,  0.96428571,  1.        ,  0.875     ,  0.875     ,\n",
       "         0.83823529,  1.        ],\n",
       "       [ 0.48      ,  0.46428571,  0.25      ,  0.375     ,  0.25      ,\n",
       "         0.16176471,  0.        ],\n",
       "       [ 0.66      ,  0.57142857,  0.5       ,  0.625     ,  0.5       ,\n",
       "         0.51470588,  0.        ],\n",
       "       [ 0.32      ,  0.46428571,  0.25      ,  0.5       ,  0.375     ,\n",
       "         0.38970588,  0.        ],\n",
       "       [ 0.46      ,  0.07142857,  0.25      ,  0.375     ,  0.125     ,\n",
       "         0.34191176,  0.        ],\n",
       "       [ 0.42      ,  0.46428571,  0.5       ,  0.625     ,  0.5       ,\n",
       "         0.45955882,  1.        ],\n",
       "       [ 0.48      ,  0.35714286,  0.75      ,  0.375     ,  0.25      ,\n",
       "         0.25      ,  1.        ],\n",
       "       [ 0.72      ,  0.75      ,  1.        ,  0.875     ,  0.75      ,\n",
       "         0.80882353,  1.        ],\n",
       "       [ 0.88      ,  0.85714286,  0.75      ,  0.75      ,  0.5       ,\n",
       "         0.29411765,  1.        ],\n",
       "       [ 0.64      ,  0.82142857,  1.        ,  0.75      ,  0.875     ,\n",
       "         0.79411765,  1.        ],\n",
       "       [ 0.66      ,  0.64285714,  0.5       ,  0.75      ,  0.625     ,\n",
       "         0.69852941,  1.        ],\n",
       "       [ 0.8       ,  0.75      ,  1.        ,  1.        ,  0.75      ,\n",
       "         0.77573529,  1.        ],\n",
       "       [ 0.78      ,  0.67857143,  0.75      ,  0.875     ,  0.875     ,\n",
       "         0.72794118,  1.        ],\n",
       "       [ 0.72      ,  0.85714286,  0.5       ,  0.625     ,  0.75      ,\n",
       "         0.71323529,  1.        ],\n",
       "       [ 0.54      ,  0.32142857,  0.5       ,  0.5       ,  0.25      ,\n",
       "         0.27205882,  1.        ],\n",
       "       [ 0.52      ,  0.21428571,  0.        ,  0.125     ,  0.25      ,\n",
       "         0.08455882,  0.        ],\n",
       "       [ 0.54      ,  0.5       ,  0.5       ,  0.625     ,  0.5       ,\n",
       "         0.25367647,  1.        ],\n",
       "       [ 0.44      ,  0.60714286,  0.25      ,  0.375     ,  0.75      ,\n",
       "         0.66911765,  0.        ],\n",
       "       [ 0.62      ,  0.67857143,  0.5       ,  0.625     ,  0.75      ,\n",
       "         0.59926471,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        ,  0.875     ,  0.875     ,\n",
       "         0.99632353,  1.        ],\n",
       "       [ 0.52      ,  0.39285714,  0.5       ,  0.625     ,  0.25      ,\n",
       "         0.17647059,  0.        ],\n",
       "       [ 0.68      ,  0.71428571,  0.75      ,  0.75      ,  0.625     ,\n",
       "         0.57720588,  1.        ],\n",
       "       [ 0.6       ,  0.64285714,  0.25      ,  0.75      ,  0.625     ,\n",
       "         0.5       ,  0.        ],\n",
       "       [ 0.44      ,  0.46428571,  0.25      ,  0.375     ,  0.5       ,\n",
       "         0.33823529,  0.        ],\n",
       "       [ 0.64      ,  0.64285714,  0.5       ,  0.5       ,  0.625     ,\n",
       "         0.29411765,  0.        ],\n",
       "       [ 0.42      ,  0.53571429,  0.75      ,  0.875     ,  0.875     ,\n",
       "         0.66176471,  1.        ],\n",
       "       [ 0.38      ,  0.28571429,  0.25      ,  0.5       ,  0.5       ,\n",
       "         0.33088235,  0.        ],\n",
       "       [ 0.18      ,  0.28571429,  0.        ,  0.125     ,  0.25      ,\n",
       "         0.25367647,  0.        ],\n",
       "       [ 0.52      ,  0.5       ,  0.25      ,  0.375     ,  0.75      ,\n",
       "         0.41176471,  0.        ],\n",
       "       [ 0.68      ,  0.67857143,  0.5       ,  0.375     ,  0.25      ,\n",
       "         0.58823529,  1.        ],\n",
       "       [ 0.88      ,  1.        ,  1.        ,  0.75      ,  1.        ,\n",
       "         0.98161765,  1.        ],\n",
       "       [ 0.36      ,  0.35714286,  0.25      ,  0.25      ,  0.625     ,\n",
       "         0.28676471,  1.        ],\n",
       "       [ 0.9       ,  0.92857143,  1.        ,  0.875     ,  0.625     ,\n",
       "         0.82352941,  1.        ],\n",
       "       [ 0.28      ,  0.32142857,  0.25      ,  0.25      ,  0.375     ,\n",
       "         0.16911765,  0.        ],\n",
       "       [ 0.2       ,  0.35714286,  0.25      ,  0.125     ,  0.25      ,\n",
       "         0.24632353,  0.        ],\n",
       "       [ 0.68      ,  0.67857143,  0.75      ,  0.5       ,  0.5       ,\n",
       "         0.66544118,  1.        ],\n",
       "       [ 0.56      ,  0.60714286,  0.        ,  0.625     ,  0.625     ,\n",
       "         0.70588235,  0.        ],\n",
       "       [ 0.38      ,  0.57142857,  0.5       ,  0.375     ,  0.5       ,\n",
       "         0.33823529,  0.        ],\n",
       "       [ 0.82      ,  0.82142857,  1.        ,  0.75      ,  0.625     ,\n",
       "         0.82352941,  1.        ],\n",
       "       [ 0.56      ,  0.5       ,  0.5       ,  0.25      ,  0.5       ,\n",
       "         0.53308824,  0.        ],\n",
       "       [ 0.48      ,  0.35714286,  0.25      ,  0.25      ,  0.375     ,\n",
       "         0.38235294,  0.        ],\n",
       "       [ 0.58      ,  0.39285714,  0.75      ,  0.875     ,  0.625     ,\n",
       "         0.53676471,  0.        ],\n",
       "       [ 0.28      ,  0.17857143,  0.25      ,  0.125     ,  0.25      ,\n",
       "         0.16176471,  0.        ],\n",
       "       [ 0.18      ,  0.28571429,  0.25      ,  0.25      ,  0.25      ,\n",
       "         0.25      ,  0.        ],\n",
       "       [ 0.32      ,  0.5       ,  0.25      ,  0.25      ,  0.375     ,\n",
       "         0.34558824,  0.        ],\n",
       "       [ 0.84      ,  0.92857143,  1.        ,  1.        ,  1.        ,\n",
       "         0.83455882,  1.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.46323529,  1.        ],\n",
       "       [ 0.64      ,  0.64285714,  1.        ,  0.875     ,  0.75      ,\n",
       "         0.65073529,  0.        ],\n",
       "       [ 0.76      ,  0.85714286,  1.        ,  1.        ,  1.        ,\n",
       "         0.84558824,  1.        ],\n",
       "       [ 0.48      ,  0.39285714,  0.25      ,  0.25      ,  0.5       ,\n",
       "         0.37132353,  0.        ],\n",
       "       [ 0.4       ,  0.42857143,  0.5       ,  0.25      ,  0.625     ,\n",
       "         0.43014706,  0.        ],\n",
       "       [ 0.2       ,  0.25      ,  0.        ,  0.5       ,  0.25      ,\n",
       "        -0.14705882,  1.        ],\n",
       "       [ 0.38      ,  0.42857143,  0.25      ,  0.25      ,  0.375     ,\n",
       "         0.38970588,  0.        ],\n",
       "       [ 0.18      ,  0.28571429,  0.5       ,  0.25      ,  0.5       ,\n",
       "         0.08088235,  0.        ],\n",
       "       [ 0.3       ,  0.5       ,  0.25      ,  0.5       ,  0.5       ,\n",
       "         0.35294118,  0.        ],\n",
       "       [ 0.82      ,  0.89285714,  0.75      ,  0.875     ,  1.        ,\n",
       "         0.81617647,  1.        ],\n",
       "       [ 0.96      ,  0.92857143,  0.75      ,  0.5       ,  0.875     ,\n",
       "         0.80882353,  1.        ],\n",
       "       [ 0.64      ,  0.78571429,  1.        ,  0.875     ,  0.75      ,\n",
       "         0.63970588,  1.        ],\n",
       "       [ 0.64      ,  0.64285714,  1.        ,  1.        ,  0.75      ,\n",
       "         0.69852941,  1.        ],\n",
       "       [ 0.08      ,  0.03571429,  0.        ,  0.125     ,  0.25      ,\n",
       "         0.05882353,  0.        ],\n",
       "       [ 0.66      ,  0.67857143,  1.        ,  0.75      ,  1.        ,\n",
       "         0.97794118,  1.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.5       ,  0.5       ,  0.25      ,\n",
       "         0.25735294,  1.        ],\n",
       "       [ 0.44      ,  0.46428571,  0.25      ,  0.125     ,  0.5       ,\n",
       "         0.46323529,  0.        ],\n",
       "       [ 0.42      ,  0.21428571,  0.        ,  0.        ,  0.375     ,\n",
       "         0.09558824,  0.        ],\n",
       "       [ 0.68      ,  0.64285714,  0.5       ,  0.625     ,  0.75      ,\n",
       "         0.61397059,  1.        ],\n",
       "       [ 0.16      ,  0.32142857,  0.25      ,  0.125     ,  0.25      ,\n",
       "         0.24264706,  0.        ],\n",
       "       [ 0.46      ,  0.35714286,  0.5       ,  0.625     ,  0.75      ,\n",
       "         0.625     ,  1.        ],\n",
       "       [ 0.24      ,  0.25      ,  0.5       ,  0.375     ,  0.5       ,\n",
       "         0.09191176,  0.        ],\n",
       "       [ 0.26      ,  0.25      ,  0.5       ,  0.25      ,  0.375     ,\n",
       "         0.16911765,  0.        ],\n",
       "       [ 0.8       ,  0.85714286,  0.75      ,  0.75      ,  0.625     ,\n",
       "         0.74632353,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\7200\\AppData\\Local\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## Hidden layer 1\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "\n",
    "## Hidden layer 2\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "\n",
    "## Output layer\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0969 - val_loss: 0.0645\n",
      "Epoch 2/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0438 - val_loss: 0.0222\n",
      "Epoch 3/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0314 - val_loss: 0.0206\n",
      "Epoch 4/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0314 - val_loss: 0.0212\n",
      "Epoch 5/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0272 - val_loss: 0.0255\n",
      "Epoch 6/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0345 - val_loss: 0.0289\n",
      "Epoch 7/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0320 - val_loss: 0.0321\n",
      "Epoch 8/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0365 - val_loss: 0.0241\n",
      "Epoch 9/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0293 - val_loss: 0.0368\n",
      "Epoch 10/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0281 - val_loss: 0.0202\n",
      "Epoch 11/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0270 - val_loss: 0.0256\n",
      "Epoch 12/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0276 - val_loss: 0.0195\n",
      "Epoch 13/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0273 - val_loss: 0.0266\n",
      "Epoch 14/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0264 - val_loss: 0.0180\n",
      "Epoch 15/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0262 - val_loss: 0.0227\n",
      "Epoch 16/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0200 - val_loss: 0.0287\n",
      "Epoch 17/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0245 - val_loss: 0.0188\n",
      "Epoch 18/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0215 - val_loss: 0.0270\n",
      "Epoch 19/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0236 - val_loss: 0.0168\n",
      "Epoch 20/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0226 - val_loss: 0.0280\n",
      "Epoch 21/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0220 - val_loss: 0.0177\n",
      "Epoch 22/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0204\n",
      "Epoch 23/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0201 - val_loss: 0.0163\n",
      "Epoch 24/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0189\n",
      "Epoch 25/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0200 - val_loss: 0.0182\n",
      "Epoch 26/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0281\n",
      "Epoch 27/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0219 - val_loss: 0.0150\n",
      "Epoch 28/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.0247\n",
      "Epoch 29/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0218 - val_loss: 0.0193\n",
      "Epoch 30/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0199 - val_loss: 0.0164\n",
      "Epoch 31/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0177 - val_loss: 0.0156\n",
      "Epoch 32/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0197 - val_loss: 0.0300\n",
      "Epoch 33/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0271 - val_loss: 0.0229\n",
      "Epoch 34/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0254 - val_loss: 0.0329\n",
      "Epoch 35/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0208 - val_loss: 0.0244\n",
      "Epoch 36/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0310\n",
      "Epoch 37/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - val_loss: 0.0133\n",
      "Epoch 38/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 39/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0174 - val_loss: 0.0198\n",
      "Epoch 40/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0205 - val_loss: 0.0163\n",
      "Epoch 41/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 42/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 43/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 44/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - val_loss: 0.0137\n",
      "Epoch 45/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 46/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 47/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 48/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 49/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 50/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 51/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 52/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 53/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - val_loss: 0.0179\n",
      "Epoch 54/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0149 - val_loss: 0.0109\n",
      "Epoch 55/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 56/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 57/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 58/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 59/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 60/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0195 - val_loss: 0.0103\n",
      "Epoch 61/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 62/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 63/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0137 - val_loss: 0.0174\n",
      "Epoch 64/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 65/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 66/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0123 - val_loss: 0.0194\n",
      "Epoch 67/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0176 - val_loss: 0.0095\n",
      "Epoch 68/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 69/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0170 - val_loss: 0.0208\n",
      "Epoch 70/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 71/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.0147\n",
      "Epoch 72/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0138\n",
      "Epoch 73/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 74/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 75/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 76/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 77/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 78/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 79/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 80/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 81/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 82/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 83/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 84/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 85/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 86/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 87/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 88/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0167\n",
      "Epoch 89/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 90/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - val_loss: 0.0083\n",
      "Epoch 91/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 92/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 93/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - val_loss: 0.0211\n",
      "Epoch 94/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0176 - val_loss: 0.0091\n",
      "Epoch 95/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0125\n",
      "Epoch 96/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 97/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - val_loss: 0.0157\n",
      "Epoch 98/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 99/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 100/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 101/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 102/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 103/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081 - val_loss: 0.0133\n",
      "Epoch 104/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 105/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 106/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.0082\n",
      "Epoch 107/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 108/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 109/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 110/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 111/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 112/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 113/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 114/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 115/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 116/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 117/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 118/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 119/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 120/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 121/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 122/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 123/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 124/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 125/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 126/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 127/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 128/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 129/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.0143\n",
      "Epoch 130/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 131/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 132/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 133/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 134/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 135/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 136/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0127 - val_loss: 0.0056\n",
      "Epoch 137/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 138/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 139/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 140/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0086 - val_loss: 0.0144\n",
      "Epoch 141/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 142/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 143/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 144/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 145/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 146/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 147/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 148/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 149/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 150/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 151/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 152/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 153/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 154/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0102 - val_loss: 0.0181\n",
      "Epoch 155/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 156/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 157/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 158/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 159/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 160/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 161/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 162/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 163/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 164/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 165/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 166/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 167/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 168/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 169/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 170/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 171/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 172/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 173/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 174/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 175/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 176/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 177/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 178/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 179/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 180/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 181/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 182/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 183/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 184/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 185/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 186/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 187/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 188/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 189/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 190/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 191/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 192/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 193/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 194/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 195/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 196/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 197/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 198/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 199/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 200/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 201/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 202/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 203/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 204/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 205/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 206/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 207/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 208/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 209/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 210/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 211/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 212/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 213/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 214/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 215/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 216/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 217/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 218/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 219/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 220/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 221/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 222/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 223/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 224/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 225/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 226/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 227/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 228/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 229/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 230/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 231/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 232/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 233/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 234/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 235/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 236/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 237/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 238/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 239/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 240/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.0043\n",
      "Epoch 241/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 242/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 243/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 244/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 245/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 246/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 247/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 248/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 249/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 250/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0106\n",
      "Epoch 251/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 252/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 253/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 254/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 255/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 256/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066 - val_loss: 0.0164\n",
      "Epoch 257/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 258/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0039\n",
      "Epoch 259/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 260/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 261/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 262/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 263/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 264/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 265/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 266/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 267/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 268/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 269/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 270/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 271/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 272/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - val_loss: 0.0039\n",
      "Epoch 273/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 274/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 275/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 276/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 277/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 278/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 279/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 280/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 281/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 282/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 283/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 284/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 285/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 286/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 287/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 288/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 289/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 290/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 291/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 292/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 293/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 294/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 295/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075 - val_loss: 0.0166\n",
      "Epoch 296/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 297/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 298/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 299/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 300/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 301/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 302/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 303/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 304/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 305/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 306/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 307/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 308/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 309/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0077\n",
      "Epoch 310/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0067 - val_loss: 0.0113\n",
      "Epoch 311/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 312/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 313/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 314/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 315/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 316/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 317/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 318/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 319/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 320/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 321/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 322/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0110\n",
      "Epoch 323/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 324/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 325/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 326/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 327/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 328/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 329/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 330/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0100 - val_loss: 0.0041\n",
      "Epoch 331/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 332/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 333/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 334/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 335/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 336/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 337/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 338/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 339/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 340/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 341/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 342/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 343/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 344/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 345/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 346/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 347/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 348/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 349/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 350/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 351/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 352/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 353/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 354/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 355/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 356/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 357/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 358/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 359/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 360/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 361/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 362/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 363/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 364/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 365/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 366/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 367/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 368/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 369/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 370/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 371/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 372/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 373/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 374/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 375/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 376/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 377/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 378/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 379/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 380/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 381/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 382/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 383/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 384/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 385/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 386/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 387/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 388/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 389/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 390/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 391/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 392/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0130 - val_loss: 0.0087\n",
      "Epoch 393/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 394/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 395/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 396/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 397/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 398/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 399/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 400/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 401/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 402/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 403/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 404/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 405/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 406/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 407/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 408/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 409/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 410/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0106 - val_loss: 0.0037\n",
      "Epoch 411/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 412/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 413/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 414/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 415/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - val_loss: 0.0139\n",
      "Epoch 416/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0085 - val_loss: 0.0037\n",
      "Epoch 417/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 418/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 419/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 420/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 421/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 422/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 423/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 424/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 425/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 426/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 427/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 428/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 429/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 430/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 431/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 432/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 433/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 434/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 435/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 436/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 437/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 438/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 439/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 440/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 441/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 442/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 443/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 444/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 445/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 446/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 447/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 448/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 449/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 450/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 451/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 452/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 453/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 454/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 455/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 456/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 457/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 458/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 459/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 460/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 461/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 462/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 463/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 464/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0080 - val_loss: 0.0161\n",
      "Epoch 465/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 466/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 467/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 468/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 469/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 470/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 471/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 472/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 473/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 474/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 475/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 476/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0096 - val_loss: 0.0039\n",
      "Epoch 477/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 478/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 479/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 480/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 481/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 482/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 483/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 484/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 485/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 486/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 487/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 488/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 489/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 490/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 491/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 492/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 493/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 494/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 495/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 496/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0090 - val_loss: 0.0037\n",
      "Epoch 497/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 498/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 499/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 500/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 501/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 502/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Epoch 503/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 504/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 505/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 506/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 507/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 508/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 509/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 510/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 511/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 512/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 513/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 514/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 515/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 516/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 517/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 518/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 519/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 520/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 521/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 522/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 523/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 524/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0105 - val_loss: 0.0079\n",
      "Epoch 525/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 526/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 527/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 528/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 529/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 530/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 531/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 532/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 533/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 534/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 535/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 536/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0138\n",
      "Epoch 537/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0148\n",
      "Epoch 538/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0096 - val_loss: 0.0040\n",
      "Epoch 539/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 540/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 541/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 542/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 543/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 544/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 545/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 546/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 547/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 548/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 549/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 550/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 551/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 552/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 553/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 554/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 555/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 556/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 557/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 558/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 559/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 560/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 561/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 562/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 563/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 564/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 565/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 566/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 567/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 568/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 569/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 570/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 571/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 572/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 573/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 574/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 575/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 576/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 577/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 578/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 579/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 580/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 581/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 582/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 583/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 584/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 585/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 586/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 587/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 588/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 589/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 590/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 591/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 592/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 593/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 594/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 595/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 596/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 597/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 598/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 599/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 600/600\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0070 - val_loss: 0.0090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=600, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ddaefdfdd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5958587150392081"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009834439493715763"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
